ignition:
  version: "2.2.0"
storage:
  filesystems:
    - name: docker
      mount:
        device: {{if eq .Provider "azure" }}/dev/disk/azure/scsi1/lun0{{else}}{{ .WorkerMountDocker }}{{end}}
        format: xfs
        wipe_filesystem: true
        label: docker

  files:
    - path: /etc/gs-release-version
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:,{{ .GSReleaseVersion }}"

    - path: /boot/coreos/first_boot
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0

    {{if eq .Provider "azure" -}}
    - path: /etc/kubernetes/config/azure.yaml
      filesystem: root
      mode: 384
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/azure-worker.yaml" }}"

    - path: /opt/bin/get-vault-token
      filesystem: root
      mode: 356
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/get-vault-token" }}"

    - path:  /etc/udev/rules.d/66-azure-storage.rules
      filesystem: root
      mode: 0644
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/66-azure-storage.rules" }}"

    {{ end -}}

    - path: /opt/k8s-extract
      filesystem: root
      mode: 356
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/k8s-extract" }}"

    - path: /etc/kubernetes/config/kubelet.yaml.tmpl
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "config/kubelet-worker.yaml.tmpl" }}"

    - path: /etc/kubernetes/config/kube-proxy.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "config/kube-proxy.yaml" }}"

    - path: /etc/kubernetes/kubeconfig/kube-proxy.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "kubeconfig/kube-proxy-worker.yaml" }}"

    - path: /etc/kubernetes/kubeconfig/kubelet.yaml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "kubeconfig/kubelet-worker.yaml" }}"

    - path: /opt/wait-for-domains
      filesystem: root
      mode: 356
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/wait-for-domains" }}"

    - path: /etc/profile.d/confirm-shutdown.sh
      filesystem: root
      mode: 292
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/confirm-shutdown.sh" }}"

    - path: /etc/profile.d/setup-terminal.sh
      filesystem: root
      mode: 292
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,ZXhwb3J0IFBTMT0iV0FSTklORzogQ09OVFJPTC1QTEFORSBXT1JLRVIgfCAkUFMxIg=="

    - path: /opt/bin/confirm
      filesystem: root
      mode: 365
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/confirm" }}"

    - path: /etc/ssh/sshd_config
      filesystem: root
      mode: 384
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/sshd_config" }}"

    - path: /opt/get-ca.sh
      filesystem: root
      mode: 504
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/get-ca.sh" }}"
    - path: /etc/sysctl.d/hardening.conf
      filesystem: root
      mode: 384
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/hardening.conf" }}"

    - path: /etc/audit/rules.d/10-docker.rules
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/10-docker.rules" }}"


    - path: /etc/systemd/system/audit-rules.service.d/10-Wait-For-Docker.conf
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/audit-docker-wait.conf" }}"

    - path: /etc/systemd/journald.conf.d/storage.conf
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/journald-storage.conf" }}"

    - path : /etc/modules-load.d/ipvs.conf
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/ipvs.conf" }}"

    - path : /etc/containerd/config.toml
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/containerd-config.toml" }}"

    - path : /etc/systemd/system/containerd.service.d/10-use-custom-config.conf
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/10-use-custom-config.conf" }}"

    - path : /etc/docker/daemon.json
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/docker-daemon.json" }}"

    - path : /etc/audit/rules.d/99-default.rules
      overwrite: true
      filesystem: root
      mode: 420
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/99-default.rules" }}"

{{ if .LogentriesEnabled }}
    - path: /opt/bin/logentries.sh
      filesystem: root
      mode: 0555
      user:
        id: 0
      group:
        id: 0
      contents:
        source: "data:text/plain;charset=utf-8;base64,{{ index .Files "conf/logentries.sh" }}"
{{ end }}

systemd:
  units:
  - name: update-engine.service
    enabled: false
    mask: true
  - name: locksmithd.service
    enabled: false
    mask: true
  - name: etcd2.service
    enabled: false
    mask: true
  - name: fleet.service
    enabled: false
    mask: true
  - name: fleet.socket
    enabled: false
    mask: true
  - name: flanneld.service
    enabled: false
    mask: true
  - name: systemd-journald.service
    dropins:
      # Better restarts: infinite retries, with a small delay
      # Because it crashes when we have falco + audit rules
      - name: 10-override.conf
        contents: |
          [Unit]
          StartLimitIntervalSec=0
          [Service]
          RestartSec=1
  - name: systemd-journal-flush.service
    # we don't want jounal data to be persisted
    enabled: false
    mask: true
  - name: systemd-modules-load.service
    enabled: true
  - name: systemd-networkd-wait-online.service
    enabled: false
    mask: true
  - name: var-lib-docker.mount
    enabled: true
    contents: |
      [Unit]
      Description=Mount disk to /var/lib/docker
      Before=docker.service

      [Mount]
      What=/dev/disk/by-label/docker
      Where=/var/lib/docker
      Type=xfs

      [Install]
      WantedBy=local-fs.targer
  - name: wait-for-domains.service
    enabled: true
    contents: |
      [Unit]
      Description=Wait for etcd and k8s API domains to be available
      StartLimitInterval=0

      [Service]
      Type=oneshot
      ExecStart=/opt/wait-for-domains

      [Install]
      WantedBy=multi-user.target
  - name: os-hardening.service
    enabled: true
    contents: |
      [Unit]
      Description=Apply os hardening

      [Service]
      Type=oneshot
      ExecStartPre=-/bin/bash -c "gpasswd -d core rkt; gpasswd -d core docker; gpasswd -d core wheel"
      ExecStartPre=/bin/bash -c "until [ -f '/etc/sysctl.d/hardening.conf' ]; do echo Waiting for sysctl file; sleep 1s;done;"
      ExecStart=/usr/sbin/sysctl -p /etc/sysctl.d/hardening.conf

      [Install]
      WantedBy=multi-user.target
  - name: get-vault-ssh-ca.service
    enabled: true
    contents: |
      [Unit]
      Description=get-vault-ssh-ca
      Wants=docker.service get-vault-ca.service get-vault-token.service
      After=docker.service get-vault-ca.service get-vault-token.service

      [Service]
      EnvironmentFile=/etc/tokens/node
      Environment=VAULT_ADDR=https://{{ .VaultDomainName }}:443
      Type=oneshot
      Restart=on-failure
      RemainAfterExit=yes
      ExecStartPre=/bin/bash -c "while ! curl -q --silent -o /dev/null https://{{ .VaultDomainName }};  do sleep 2s;echo wait for Vault;done;"
      ExecStart=/bin/bash -c '\
         result=$(curl -o /etc/ssh/trusted-user-ca-keys.pem \
                   --header "X-Vault-Token: $VAULT_TOKEN" \
                   $VAULT_ADDR/v1/ssh-client-signer/public_key);\
         [ $? -ne 0 ] && echo "Failed to fetch CA ssh public key" && exit 1 || echo "Sucesfully retrieved CA ssh public key";'
      [Install]
      WantedBy=multi-user.target
  - name: k8s-setup-kubelet-config.service
    enabled: true
    contents: |
      [Unit]
      Description=k8s-setup-kubelet-config Service
      After=k8s-setup-network-env.service docker.service
      Requires=k8s-setup-network-env.service docker.service

      [Service]
      Type=oneshot
      RemainAfterExit=yes
      TimeoutStartSec=0
      Environment=IMAGE={{.DockerRegistry}}/giantswarm/alpine:3.16.1-envsubst
      ExecStart=docker run --rm \
        --env-file /etc/network-environment \
        -v /etc/kubernetes/config/:/etc/kubernetes/config/ \
        $IMAGE \
        ash -c "cat /etc/kubernetes/config/kubelet.yaml.tmpl |envsubst >/etc/kubernetes/config/kubelet.yaml"

      [Install]
      WantedBy=multi-user.target
  - name: get-vault-ca.service
    enabled: true
    contents: |
      [Unit]
      Description=get vault-ca into trusted certs
      Before=kubelet-certs.service get-vault-token.service
      After=wait-for-domains.service
      Wants=wait-for-domains.service

      [Service]
      Type=oneshot
      Restart=on-failure
      ExecStartPre=/bin/bash -c "while ! curl -k -q --silent -o /dev/null https://{{ .VaultDomainName }};  do sleep 2s;echo wait for Vault;done;"
      ExecStartPre=/opt/get-ca.sh {{ .VaultDomainName }}:443 /etc/ssl/certs/gs-ca.pem
      ExecStart=/sbin/update-ca-certificates
      RemainAfterExit=yes

      [Install]
      WantedBy=multi-user.target

  {{ if eq .Provider "aws" -}}
  - name: get-vault-token.service
    enabled: true
    contents: |
      [Unit]
      Description=get-vault-token
      Requires=get-vault-ca.service k8s-setup-network-env.service docker.service wait-for-domains.service
      After=get-vault-ca.service k8s-setup-network-env.service docker.service wait-for-domains.service

      [Service]
      EnvironmentFile=/etc/environment
      EnvironmentFile=/etc/network-environment
      Environment=VAULT_ADDR=https://{{ .VaultDomainName }}
      Environment=CLUSTER_NAME={{ .ClusterName }}
      Type=oneshot
      RemainAfterExit=yes
      ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/ssl/
      ExecStartPre=/usr/bin/mkdir -p /etc/tokens
      ExecStartPre=/bin/bash -c "while ! docker run --rm -v /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt {{.DockerRegistry}}/giantswarm/curl:7.67.0 -k -q --silent -o /dev/null https://{{ .VaultDomainName }};  do sleep 2s;echo wait for Vault;done;"
      ExecStart=/bin/bash -e -c '\
          login_info=$(\
          docker run --rm -i\
          -v /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt\
          --net host\
          --privileged=true\
          -e VAULT_ADDR\
          -e CLUSTER_NAME\
          {{.DockerRegistry}}/giantswarm/vault:1.6.1\
          login -method=aws role=$${CLUSTER_NAME}-worker region={{ .AWSRegion }} -format=json);\
          vault_token=$(echo $${login_info} | jq -r .auth.client_token);\
          echo "VAULT_TOKEN=$${vault_token}" > /etc/tokens/node;\
          '
      [Install]
      WantedBy=multi-user.target
  {{- end }}

  {{ if eq .Provider "azure" -}}
  - name: get-vault-token.service
    enabled: true
    contents: |
      [Unit]
      Description=get-vault-token
      Wants=get-vault-ca.service k8s-setup-network-env.service docker.service wait-for-domains.service
      After=get-vault-ca.service k8s-setup-network-env.service docker.service wait-for-domains.service

      [Service]
      EnvironmentFile=/etc/environment
      EnvironmentFile=/etc/network-environment
      Type=oneshot
      RemainAfterExit=yes
      ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/ssl/
      ExecStartPre=/usr/bin/mkdir -p /etc/tokens
      ExecStartPre=/bin/bash -c "while ! docker run --rm -v /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt {{.DockerRegistry}}/giantswarm/curl:7.67.0 -k -q --silent -o /dev/null https://{{ .VaultDomainName }};  do sleep 2s;echo wait for Vault;done;"
      ExecStart=/opt/bin/get-vault-token

      [Install]
      WantedBy=multi-user.target
  {{- end }}

  - name: docker.service
    enabled: true
    dropins:
    - name: 10-giantswarm-extra-args.conf
      contents: |
        [Unit]
        Requires=var-lib-docker.mount
        After=var-lib-docker.mount

        [Service]
        Environment="DOCKER_CGROUPS=--log-opt max-size=50m --log-opt max-file=2 --log-opt labels=io.kubernetes.container.hash,io.kubernetes.container.name,io.kubernetes.pod.name,io.kubernetes.pod.namespace,io.kubernetes.pod.uid"
        Environment="DOCKER_OPT_BIP=--bip={{ .DockerCIDR }}"
        Environment="DOCKER_OPTS=--live-restore --userland-proxy=false --icc=false --experimental=true --metrics-addr=0.0.0.0:9323"
{{if eq .Provider "aws" }}
  - name: set-hostname.service
    enabled: true
    contents: |
      [Unit]
      Description=set proper hostname for k8s
      Requires=wait-for-domains.service
      After=wait-for-domains.service
      Before=k8s-kubelet.service

      [Service]
      Type=oneshot
      RemainAfterExit=yes
      ExecStart=/bin/bash -c "hostnamectl set-hostname $(curl http://169.254.169.254/latest/meta-data/local-hostname)"

      [Install]
      WantedBy=multi-user.target
{{ if ne .AdditionalTags "" }}
  - name: tag-ebs-volumes.service
    enabled: false
    contents: |
      [Unit]
      Description=Tag all EBS volumes attached to the machine with proper tags
      After=docker.service
      Requires=docker.service

      [Service]
      Type=oneshot
      EnvironmentFile=/etc/environment
      Environment=IMAGE={{.DockerRegistry}}/giantswarm/awscli:2.0.24
      Environment=NAME=%p.service
      ExecStartPre=-/usr/bin/docker stop  $NAME
      ExecStartPre=-/usr/bin/docker rm  $NAME
      ExecStartPre=-/usr/bin/docker pull $IMAGE
      ExecStart=/usr/bin/docker run  --network=host --entrypoint /bin/bash $IMAGE -c "export instance_id=$(curl http://169.254.169.254/latest/meta-data/instance-id -qs); export volume_ids=$(aws ec2 describe-volumes --filter Name=attachment.instance-id,Values=$instance_id --query Volumes[*].VolumeId --out=text) ; aws ec2 create-tags --resources $volume_ids --tags {{.AdditionalTags}}; echo tagged volumes $volume_ids"

      [Install]
      WantedBy=multi-user.target
  - name: tag-ebs-volumes.timer
    enabled: true
    contents: |
      [Unit]
      Description=Execute tag-ebs-volumes.service every hour

      [Timer]
      OnCalendar=*-*-* *:00:00 UTC

      [Install]
      WantedBy=multi-user.target
{{end}}
{{end}}
  - name: k8s-setup-network-env.service
    enabled: true
    contents: |
      [Unit]
      Description=k8s-setup-network-env Service
      Wants=network.target docker.service
      After=network.target docker.service

      [Service]
      Type=oneshot
      RemainAfterExit=yes
      TimeoutStartSec=0
      Environment="IMAGE={{.DockerRegistry}}/giantswarm/k8s-setup-network-environment:0.2.0"
      Environment="NAME=%p.service"
      Environment="NETWORK_CONFIG_CONTAINER="
      ExecStartPre=/usr/bin/docker pull $IMAGE
      ExecStartPre=-/usr/bin/docker stop -t 10 $NAME
      ExecStartPre=-/usr/bin/docker rm -f $NAME
      ExecStart=/usr/bin/docker run --rm --net=host -v /etc:/etc --name $NAME $IMAGE --verbose
      ExecStop=-/usr/bin/docker stop -t 10 $NAME
      ExecStopPost=-/usr/bin/docker rm -f $NAME

      [Install]
      WantedBy=multi-user.target
  - name: etcd-client-certs.service
    enabled: true
    contents: |
      [Unit]
      Description=gen etcd client certs
      Wants=get-vault-ca.service k8s-setup-network-env.service docker.service wait-for-domains.service get-vault-token.service{{if eq .Provider "azure" }} waagent.service{{ end }}
      After=get-vault-ca.service k8s-setup-network-env.service docker.service wait-for-domains.service get-vault-token.service{{if eq .Provider "azure" }} waagent.service{{end}}

      [Service]
      EnvironmentFile=/etc/environment
      EnvironmentFile=/etc/network-environment
      EnvironmentFile=/etc/tokens/node
      Type=oneshot
      RemainAfterExit=yes
      ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/ssl/etcd/
      ExecStartPre=/bin/bash -c "while ! docker run --rm -v /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt {{.DockerRegistry}}/giantswarm/curl:7.67.0 -k -q --silent -o /dev/null https://{{ .VaultDomainName }};  do sleep 2s;echo wait for Vault;done;"
      ExecStart=/usr/bin/docker run \
      --rm \
      --net=host \
      -v /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt \
      -v /etc/kubernetes/ssl/etcd/:/etc/kubernetes/ssl/etcd/ \
      {{.DockerRegistry}}/giantswarm/certctl:943e40d9c36efc2eec76783d48a891fc6f323493 \
      issue \
      --vault-addr=https://{{ .VaultDomainName }} \
      --vault-token=${VAULT_TOKEN} \
      --cluster-id=g8s \
      --common-name=calico.{{ .BaseDomain }} \
      --ttl=8760h \
      --ip-sans=127.0.0.1,${DEFAULT_IPV4} \
      --alt-names=localhost \
      --ca-file=/etc/kubernetes/ssl/etcd/client-ca.pem \
      --crt-file=/etc/kubernetes/ssl/etcd/client-crt.pem \
      --key-file=/etc/kubernetes/ssl/etcd/client-key.pem

      [Install]
      WantedBy=multi-user.target
  - name: kubelet-certs.service
    enabled: true
    contents: |
      [Unit]
      Description=api-certs
      Wants=get-vault-ca.service k8s-setup-network-env.service docker.service wait-for-domains.service get-vault-token.service{{if eq .Provider "azure" }} waagent.service{{end}}
      After=get-vault-ca.service k8s-setup-network-env.service docker.service wait-for-domains.service get-vault-token.service{{if eq .Provider "azure" }} waagent.service{{end}}

      [Service]
      EnvironmentFile=/etc/environment
      EnvironmentFile=/etc/network-environment
      EnvironmentFile=/etc/tokens/node
      Type=oneshot
      Restart=on-failure
      RemainAfterExit=yes
      ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/ssl/
      ExecStartPre=/bin/bash -c "while ! docker run --rm -v /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt {{.DockerRegistry}}/giantswarm/curl:7.67.0 -k -q --silent -o /dev/null https://{{ .VaultDomainName }};  do sleep 2s;echo wait for Vault;done;"
      ExecStart=/usr/bin/docker run \
      --rm \
      --net=host \
      -v /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt \
      -v /etc/kubernetes/ssl/:/etc/kubernetes/ssl/ \
      {{.DockerRegistry}}/giantswarm/certctl:943e40d9c36efc2eec76783d48a891fc6f323493 \
      issue \
      --vault-addr=https://{{ .VaultDomainName }} \
      --vault-token=${VAULT_TOKEN} \
      --cluster-id=g8s \
      --common-name={{ .APIDomainName }} \
      --ttl=8760h \
      --crt-file=/etc/kubernetes/ssl/worker-crt.pem \
      --key-file=/etc/kubernetes/ssl/worker-key.pem \
      --ca-file=/etc/kubernetes/ssl/worker-ca.pem

      [Install]
      WantedBy=multi-user.target
  - name: k8s-extract.service 
    enabled: true
    contents: |
      [Unit]
      Description=Pulls hyperkube binary from image to local FS
      After=docker.service
      Requires=docker.service
      [Service]
      Type=oneshot
      RemainAfterExit=yes
      TimeoutStartSec=0
      Environment="IMAGE={{.DockerRegistry}}/giantswarm/hyperkube:{{.K8sVersion}}"
      Environment="NAME=%p.service"
      ExecStartPre=/usr/bin/mkdir -p /opt/bin/
      ExecStartPre=/usr/bin/docker pull $IMAGE
      ExecStartPre=-/usr/bin/docker rm $NAME
      ExecStartPre=-/usr/bin/docker create --name $NAME $IMAGE /kubectl
      ExecStart=/opt/k8s-extract $NAME
      ExecStopPost=-/usr/bin/docker rm $NAME
      [Install]
      WantedBy=multi-user.target
  - name: k8s-kubelet.service
    enabled: true
    contents: |
      [Unit]
      Description=k8s-kubelet
      StartLimitIntervalSec=0
      After=k8s-setup-network-env.service docker.service kubelet-certs.service wait-for-domains.service k8s-setup-kubelet-config.service k8s-extract.service
      Wants=k8s-setup-network-env.service docker.service kubelet-certs.service wait-for-domains.service k8s-setup-kubelet-config.service k8s-extract.service

      [Service]
      TimeoutStartSec=300
      Restart=always
      RestartSec=0
      TimeoutStopSec=10
      EnvironmentFile=/etc/network-environment
      Environment="NAME=%p.service"
      Environment="ETCD_CA_CERT_FILE=/etc/kubernetes/ssl/etcd/client-ca.pem"
      Environment="ETCD_CERT_FILE=/etc/kubernetes/ssl/etcd/client-crt.pem"
      Environment="ETCD_KEY_FILE=/etc/kubernetes/ssl/etcd/client-key.pem"
      ExecStart=/opt/bin/kubelet \
      --config=/etc/kubernetes/config/kubelet.yaml \
      --node-ip=${DEFAULT_IPV4} \
      --container-runtime=remote \
      --container-runtime-endpoint=unix:///run/containerd/containerd.sock \
      --logtostderr=true \
      {{if eq .Provider "aws" -}}
      --cloud-provider=external \
      --pod-infra-container-image={{.DockerRegistry}}/{{ .PodInfraImage }} \
      {{ else -}}
      --cloud-provider=external \
      {{ end -}}
      --register-node=true \
      --kubeconfig=/etc/kubernetes/kubeconfig/kubelet.yaml \
      --node-labels="node.kubernetes.io/worker,role=worker,ip=${DEFAULT_IPV4}" \
      --v=2
      ExecStop=-/usr/bin/docker stop -t 10 $NAME
      ExecStopPost=-/usr/bin/docker rm -f $NAME

      [Install]
      WantedBy=multi-user.target
  - name: k8s-label-node.service
    enabled: true
    contents: |
      [Unit]
      Description=Adds labels to the node after kubelet startup
      After=k8s-kubelet.service
      Wants=k8s-kubelet.service
      [Service]
      Type=oneshot
      RemainAfterExit=yes
      Environment="KUBECTL=/opt/bin/kubectl --kubeconfig /etc/kubernetes/kubeconfig/kubelet.yaml"
      ExecStart=/bin/sh -c '\
        while [ "$($KUBECTL get nodes $(hostname | tr '[:upper:]' '[:lower:]')| wc -l)" -lt "1" ]; do echo "Waiting for healthy k8s" && sleep 20s;done; \
        $KUBECTL label nodes --overwrite $(hostname | tr '[:upper:]' '[:lower:]') node-role.kubernetes.io/worker=""; \
        $KUBECTL label nodes --overwrite $(hostname | tr '[:upper:]' '[:lower:]') kubernetes.io/role=worker'
      [Install]
      WantedBy=multi-user.target
  - name: auditd.service
    enabled: true
{{ if .LogentriesEnabled }}
  - name: logentries.service
    enabled: true
    contents: |
      [Unit]
      Description=Logentries

      [Service]
      Environment=LOGENTRIES_PREFIX={{ .LogentriesPrefix }}
      Environment=LOGENTRIES_TOKEN={{ .LogentriesToken }}
      ExecStart=/bin/sh /opt/bin/logentries.sh ${LOGENTRIES_PREFIX} ${LOGENTRIES_TOKEN}

      [Install]
      WantedBy=multi-user.target
{{ end }}
{{ if eq .Provider "aws" }}
networkd:
  units:
  - name: 00-aws-cni.network
    contents: |
      [Match]
      Name=eth[1-9]*

      [Link]
      Unmanaged=yes
{{end}}
passwd:
  users:
  - name: giantswarm
    groups:
    - "sudo"
    - "docker"
{{ range .Users }}
{{- if eq .role "SRE" "PE" }}
  - name: "{{ .name }}"
    groups:
      - "sudo"
      - "docker"
    sshAuthorizedKeys:
      {{- range .sshAuthorizedKeys }}
      - {{ . }}
      {{- end }}
{{- end }}
{{- end }}
